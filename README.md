# Лабораторная работа №3  
## Классификация. Нейронные сети

---

### Введение

Цель работы: изучение методов классификации данных, реализованные в библиотеке Scikit-Learn, а также ознакомление с нейронными сетями с использованием библиотек TensorFlow и TensorBoard. 

Постановка задачи:

  Необходимо выбрать и подготовить датасет для классификации, затем построить классификационные модели с помощью пяти методов:
  - Наивный Байесовский классификатор (GaussianNB, MultinomialNB, ComplementNB, BernoulliNB);
  - Деревья решений (Decision Tree);
  - Линейный дискриминантный анализ (Linear Discriminant Analysis);
  - Метод опорных векторов (Support Vector Machines);
  - Метод ближайших соседей (k-Nearest Neighbors);

  Затем сравните качество работы классификаторов с помощью следующих метрик:
  - Accuracy (точность),
  - Precision (доля правильно классифицированных положительных примеров),
  - Recall (чувствительность, доля верно найденных положительных примеров),
  - F1-Score (среднее гармоническое precision и recall),
  - Площадь под кривой ROC (AUC-ROC).

  Настройте гиперпараметры каждого метода и проведите исследование влияния различных параметров на качество классификации.

  Реализуйте и протестируйте нейронную сеть на TensorFlow, исследуйте эффект настройки гиперпараметров и визуализируйте процесс обучения с помощью инструмента TensorBoard.

  (Опционально на дополнительные баллы): Постройте нейронную сеть для классификации на TensorFlow. Организуйте 5-кратную кросс-валидацию для надежной оценки качества. Методом Grid Search с кросс-валидацией подберите оптимальную скорость обучения (3 различных значения) и архитектуру сети (3 варианта). Настройте TensorBoard для отслеживания accuracy / loss на каждом фолде. Сравнения различных конфигураций модели. Сравните финальную accuracy с baseline-моделью и проанализируйте эффект от настройки параметров.

---

### Выбор и подготовка датасета

Для анализа использован датасет 'spotify_churn_dataset.csv', содержащий информацию о 8000 пользователях музыкального стримингового сервиса. Каждая запись включает 12 признаков:

- Категориальные: gender, country, subscription_type, device_type;
- Числовые: age, listening_time, songs_played_per_day, skip_rate, ads_listened_per_week, offline_listening;
- Идентификатор: user_id (удалён как неинформативный);
- Целевой признак: is_churned — бинарная переменная (0 — остался, 1 — ушёл).

Пропусков в данных нет. Все категориальные признаки закодированы с помощью OneHotEncoder, числовые — нормализованы через MinMaxScaler (в части экспериментов использовался StandardScaler). Для борьбы с дисбалансом применены веса классов.

---

### Разбиение выборки

Данные разбиты на обучающую (80%) и тестовую (20%) выборки с стратификацией по целевому признаку, чтобы сохранить пропорции классов в обеих частях.

---

### Методы классификации

В работе протестированы следующие алгоритмы:

- Наивный байес: GaussianNB, MultinomialNB, BernoulliNB, ComplementNB;
- Метод опорных векторов (SVM) с ядрами rbf и linear;
- Метод k-ближайших соседей (KNN);
- Дерево решений;
- Линейный дискриминантный анализ (LDA).

Базовая оценка показала, что большинство моделей (особенно наивные байесы и LDA) выдают нулевой recall и precision, так как они предсказывают только класс 0 — из-за дисбаланса. Исключение составили ComplementNB, SVM и KNN, которые хотя бы частично улавливают ушедших пользователей.

---

### Настройка гиперпараметров

Для каждой модели проведён поиск лучших гиперпараметров с помощью GridSearchCV и 5-кратной стратифицированной кросс-валидации с метрикой F1-score.

Результаты показали:
- ComplementNB с alpha=1.0 дал F1 = 0.343;
- SVM с C=1, kernel=rbf, gamma=auto — F1 = 0.342;
- Дерево решений с max_depth=3, criterion='entropy — F1 = 0.371 на кросс-валидации, но на тесте упало до 0.303;
- KNN показал высокую точность, но низкий recall — F1 = 0.248.

Это подтверждает, что подбор параметров действительно влияет на качество, особенно для моделей, чувствительных к настройкам (SVM, деревья). Однако даже после настройки F1-score остаётся низким — задача сложна из-за недостаточной информативности признаков.

---

### Нейронная сеть на TensorFlow

Обучена полносвязная нейронная сеть с архитектурой (128 64 1), ReLU-активацией, Dropout (30%) и сигмоидой на выходе. Оптимизатор — Adam, функция потерь — бинарная кросс-энтропия. Обучение велось с ранней остановкой (EarlyStopping) и весами классов для балансировки.

Модель показала **F1 ≈ 0.34**, что сопоставимо с ComplementNB. В ходе более глубокого поиска гиперпараметров (архитектура, learning rate, dropout) лучшей оказалась конфигурация (128, 64, 32), lr=1e-4, dropout=0.3, которая дала среднюю accuracy 57.7% по кросс-валидации.

После обучения на всех данных финальная модель достигла accuracy = 60.2%, но это значение следует воспринимать с осторожностью, так как оценка выполнена на тех же данных, что и обучение, что ведёт к оптимистичной оценке. Визуализация обучения через TensorBoard показала устойчивое снижение loss и рост AUC на валидации, без явных признаков переобучения.

---

### Сравнительный анализ

| Модель           | Accuracy | Precision | Recall | F1    | AUC   |
|------------------|----------|-----------|--------|-------|-------|
| ComplementNB     | 0.531    | 0.271     | 0.483  | 0.348 | 0.503 |
| NeuralNet (baseline) | 0.532 | 0.268     | 0.469  | 0.341 | 0.510 |
| SVM              | 0.546    | 0.266     | 0.430  | 0.329 | 0.512 |
| DecisionTree     | 0.563    | 0.258     | 0.367  | 0.303 | 0.483 |
| KNN              | 0.667    | 0.298     | 0.213  | 0.248 | 0.556 |
| MultinomialNB    | 0.741    | 0.000     | 0.000  | 0.000 | 0.503 |

Несмотря на высокую точность у наивных байесов и KNN, их F1 близок к нулю или низок, что делает их непригодными для задачи, где важно обнаруживать ушедших пользователей. Лучшими по F1-score оказались ComplementNB и нейросеть, причём нейросеть немного выигрывает по AUC. Однако разница незначительна, а интерпретируемость ComplementNB гораздо выше.

Вывод: для данного датасета ни одна модель не достигает высокого качества классификации оттока. Наилучший компромисс между сложностью и качеством — ComplementNB, так как он прост, быстр и показывает стабильный F1 = 0.35. Нейросеть не даёт существенного прироста, что говорит о том, что проблема, скорее всего, в недостатке предиктивной силы признаков, а не в слабости моделей.

---

### Заключение

Лабораторная работа продемонстрировала полный цикл решения задачи бинарной классификации при дисбалансе классов: от загрузки и препроцессинга данных до обучения, настройки гиперпараметров и сравнительного анализа моделей. Показано, что точность (accuracy) может вводить в заблуждение при несбалансированных данных, а F1-score и ROC-AUC — более адекватные метрики. Несмотря на применение современных методов, включая нейронные сети, качество предсказания оттока осталось умеренным, что указывает на необходимость либо расширения набора признаков (например, за счёт временных трендов), либо изменения постановки задачи (например, ранжирование вместо классификации).

---

### Список источников

1. Scikit-learn documentation: https://scikit-learn.org  
2. TensorFlow/Keras documentation: https://www.tensorflow.org  

---

### Приложение

Полный код реализации приведён в ноутбуке [`Untitled-1.ipynb`](./Untitled-1.ipynb).
